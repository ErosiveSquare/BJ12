import streamlit as st
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import os
import math
from sklearn.preprocessing import MinMaxScaler
from scipy.interpolate import CubicSpline
import plotly.graph_objects as go

#é¢„æµ‹ç•Œé¢è¿™ä¸ªæ˜¯
class PositionalEncoding(nn.Module):
    def __init__(self, d_model, dropout=0.1, max_len=5000):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(p=dropout)
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)

    def forward(self, x):
        x = x + self.pe[:x.size(0), :]
        return self.dropout(x)


class TemporalAttention(nn.Module):
    def __init__(self, hidden_size):
        super().__init__()
        self.W = nn.Linear(hidden_size, hidden_size)
        self.v = nn.Parameter(torch.rand(hidden_size))
        self.softmax = nn.Softmax(dim=1)

    def forward(self, features):
        uh = torch.tanh(self.W(features))
        scores = torch.matmul(uh, self.v)
        attention_weights = self.softmax(scores)
        context = torch.bmm(attention_weights.unsqueeze(1), features).squeeze(1)
        return context


class UltimateHybridModel(nn.Module):
    def __init__(self, n_features, model_dim, num_heads, num_encoder_layers, gru_hidden_size, gru_layers, dropout,
                 output_seq_len):
        super().__init__()
        self.input_projection = nn.Linear(n_features, model_dim)
        self.pos_encoder = PositionalEncoding(model_dim, dropout)
        encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, dim_feedforward=model_dim * 4,
                                                   dropout=dropout, batch_first=True, activation='gelu')
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)
        self.gru = nn.GRU(model_dim, gru_hidden_size, gru_layers, batch_first=True, dropout=dropout, bidirectional=True)
        self.transformer_attention = TemporalAttention(model_dim)
        fused_dim = 2 * gru_hidden_size + model_dim
        self.output_layer = nn.Sequential(
            nn.Linear(fused_dim, fused_dim // 2),
            nn.BatchNorm1d(fused_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(fused_dim // 2, output_seq_len)
        )

    def forward(self, x):
        x_projected = self.input_projection(x)
        x_pos = self.pos_encoder(x_projected.permute(1, 0, 2)).permute(1, 0, 2)
        transformer_output = self.transformer_encoder(x_pos)
        transformer_output = x_pos + transformer_output
        gru_output, _ = self.gru(transformer_output)
        gru_last_hidden = gru_output[:, -1, :]
        transformer_context = self.transformer_attention(transformer_output)
        fused_features = torch.cat([gru_last_hidden, transformer_context], dim=1)
        prediction = self.output_layer(fused_features)
        return prediction


# ==============================================================================
# 2. Streamlit ç¼“å­˜ã€é¢„æµ‹å’Œæ’å€¼å‡½æ•°
# ==============================================================================

@st.cache_resource
def load_model_and_artifacts(model_path):
    """
    åŠ è½½æ¨¡å‹å’Œç›¸å…³æ–‡ä»¶ï¼Œå¹¶ä½¿ç”¨ Streamlit çš„ç¼“å­˜ã€‚
    """
    if not os.path.exists(model_path):
        st.error(f"é”™è¯¯: æ¨¡å‹æ–‡ä»¶æœªåœ¨ '{model_path}' æ‰¾åˆ°ï¼è¯·æ£€æŸ¥è·¯å¾„ã€‚")
        return None

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    try:
        artifacts = torch.load(model_path, map_location=device, weights_only=False)
    except Exception as e:
        st.error(f"åŠ è½½æ¨¡å‹æ–‡ä»¶å¤±è´¥: {e}")
        st.info("è¿™å¯èƒ½æ˜¯ç”±äº PyTorch ç‰ˆæœ¬ä¸å…¼å®¹æˆ–æ–‡ä»¶æŸåã€‚è¯·ç¡®ä¿æ‚¨ä½¿ç”¨çš„æ˜¯ä¸è®­ç»ƒæ¨¡å‹æ—¶ç›¸è¿‘çš„ PyTorch ç‰ˆæœ¬ã€‚")
        st.stop()

    return artifacts, device


def predict(artifacts, device, raw_input_data):
    """
    ä¿®æ”¹åçš„é¢„æµ‹å‡½æ•°ï¼Œæ¥æ”¶åŠ è½½å¥½çš„ artifacts å’Œæ•°æ®ã€‚
    """
    default_config = {
        'N_FEATURES': 7, 'INPUT_SEQ_LEN': 168, 'OUTPUT_SEQ_LEN': 24,
        'MODEL_DIM': 128, 'NUM_HEADS': 8, 'NUM_ENCODER_LAYERS': 4,
        'GRU_HIDDEN_SIZE': 128, 'GRU_LAYERS': 2, 'DROPOUT_RATE': 0.25,
    }
    saved_config = artifacts.get('config_dict', {})
    final_config = default_config.copy()
    final_config.update(saved_config)

    feature_scalers = artifacts['feature_scalers']
    target_scaler = artifacts['target_scaler']
    model_state_dict = artifacts['model_state_dict']

    model = UltimateHybridModel(
        n_features=final_config['N_FEATURES'], model_dim=final_config['MODEL_DIM'],
        num_heads=final_config['NUM_HEADS'], num_encoder_layers=final_config['NUM_ENCODER_LAYERS'],
        gru_hidden_size=final_config['GRU_HIDDEN_SIZE'], gru_layers=final_config['GRU_LAYERS'],
        dropout=final_config['DROPOUT_RATE'], output_seq_len=final_config['OUTPUT_SEQ_LEN']
    )
    model.load_state_dict(model_state_dict)
    model.to(device)
    model.eval()

    scaled_input_data = raw_input_data.copy()
    for col in scaled_input_data.columns:
        if col in feature_scalers:
            scaler = feature_scalers[col]
            scaled_input_data[col] = scaler.transform(scaled_input_data[[col]])

    input_tensor = torch.from_numpy(scaled_input_data.values).float().unsqueeze(0).to(device)

    with torch.no_grad():
        scaled_prediction = model(input_tensor)

    prediction_numpy = scaled_prediction.cpu().numpy()
    final_prediction = target_scaler.inverse_transform(prediction_numpy)

    return final_prediction.flatten()


def interpolate_to_15min(hourly_prices):
    """
    ä½¿ç”¨ä¸‰æ¬¡æ ·æ¡æ’å€¼å°†æ¯å°æ—¶æ•°æ®è½¬æ¢ä¸º15åˆ†é’Ÿæ•°æ®ã€‚
    """
    # å®šä¹‰åŸå§‹æ—¶é—´ç‚¹ (0-23å°æ—¶) å’Œæ–°çš„æ—¶é—´ç‚¹ (0, 0.25, ..., 23.75)
    hourly_time_points = np.arange(24)
    finer_time_points = np.arange(0, 24, 0.25)

    # åˆ›å»ºä¸‰æ¬¡æ ·æ¡æ’å€¼å‡½æ•°
    cs = CubicSpline(hourly_time_points, hourly_prices)

    # è®¡ç®—15åˆ†é’Ÿç²’åº¦çš„ä»·æ ¼
    finer_prices = cs(finer_time_points)

    # åˆ›å»ºæ—¶é—´æ ‡ç­¾
    time_labels = []
    for h in range(24):
        for m in [0, 15, 30, 45]:
            if h == 0 and m == 0:
                # ä¸ºäº†ä¸æ¯å°æ—¶çš„+1hå¯¹é½ï¼Œæˆ‘ä»¬æŠŠç¬¬ä¸€ä¸ªç‚¹æ ‡è®°ä¸º+1h
                time_labels.append(f"+1h 0m")
                continue
            time_labels.append(f"+{h + 1}h {m}m")

    # å› ä¸ºarange(0, 24, 0.25)ä¼šäº§ç”Ÿ96ä¸ªç‚¹ï¼Œæ‰€ä»¥éœ€è¦96ä¸ªæ ‡ç­¾
    # ç¬¬ä¸€ä¸ªæ ‡ç­¾æ˜¯ "+1h 0m",æœ€åä¸€ä¸ªæ˜¯ "+24h 45m"
    # ä¸ºäº†UIæ˜¾ç¤ºæ›´ç›´è§‚ï¼Œæˆ‘ä»¬å°†ç¬¬ä¸€ä¸ªç‚¹æ ‡è®°ä¸º+1hï¼Œæœ€åä¸€ä¸ªç‚¹æ ‡è®°ä¸º+25h
    # ä¿®æ­£æ—¶é—´æ ‡ç­¾ç”Ÿæˆé€»è¾‘
    time_labels = []
    for i, t in enumerate(finer_time_points):
        hour = int(t) + 1
        minute = int((t * 60) % 60)
        time_labels.append(f"+{hour}h {minute:02d}m")

    return finer_prices, time_labels, finer_time_points


# ==============================================================================
# 3. Streamlit åº”ç”¨ç•Œé¢
# ==============================================================================
# --- é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(
    page_title="ç”µä»·é¢„æµ‹ç³»ç»Ÿ | AI-Powered Price Forecaster",
    page_icon="âš¡",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- ä¸»æ ‡é¢˜å’Œä»‹ç» ---
st.title("ğŸ“ˆ æ™ºèƒ½ç”µä»·é¢„æµ‹ç³»ç»Ÿ")
st.markdown("""
åŸºäº **Transformer & GRU** æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹çš„ç”µä»·é¢„æµ‹å·¥å…·ã€‚
æœ¬ç³»ç»Ÿèƒ½å¤Ÿå¯¹æœªæ¥24å°æ—¶çš„ç”µä»·è¿›è¡Œå°æ—¶çº§ç²¾å‡†é¢„æµ‹ï¼Œå¹¶æä¾›15åˆ†é’Ÿç²’åº¦çš„å¹³æ»‘è¶‹åŠ¿åˆ†æã€‚
""")
st.markdown("---")

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("âš™ï¸ å‚æ•°é…ç½®")
    MODEL_PATH = "saved_model/model_and_scalers_ultimate.pth"
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ æ‚¨çš„è¾“å…¥æ•°æ® (CSV or XLSX)",
        type=['csv', 'xlsx']
    )

    with st.expander("ğŸ’¡ å¦‚ä½•å‡†å¤‡è¾“å…¥æ•°æ®?", expanded=False):
        st.markdown("""
        1.  **æ–‡ä»¶æ ¼å¼**: æ”¯æŒ CSV æˆ– Excel (`.xlsx`) æ–‡ä»¶ã€‚
        2.  **æ•°æ®è¡Œæ•°**: æ–‡ä»¶å¿…é¡» **ä¸å¤šä¸å°‘ï¼Œæ­£å¥½åŒ…å« 168 è¡Œ** å†å²æ•°æ®ï¼Œä»£è¡¨è¿‡å»7å¤©æ¯å°æ—¶çš„æ•°æ®ç‚¹ã€‚
        3.  **æ•°æ®åˆ—æ•°ä¸é¡ºåº**: æ–‡ä»¶å¿…é¡»åŒ…å«ä»¥ä¸‹ **7ä¸ªç‰¹å¾åˆ—**ï¼Œä¸”**åç§°å’Œé¡ºåº**å¿…é¡»å®Œå…¨ä¸€è‡´:
        """)
        st.code("price, price_delta, load, load_delta, load_capacity_ratio, predicted_load, hour")
        st.warning("ä»»ä½•æ ¼å¼ä¸ç¬¦éƒ½å¯èƒ½å¯¼è‡´é¢„æµ‹å¤±è´¥æˆ–ç»“æœä¸å‡†ç¡®ã€‚")
    st.info("å½“å‰æ¨¡å‹è·¯å¾„: `saved_model/model_and_scalers_ultimate.pth`")

# --- åŠ è½½æ¨¡å‹ ---
artifacts_tuple = load_model_and_artifacts(MODEL_PATH)
if artifacts_tuple is None:
    st.stop()
artifacts, device = artifacts_tuple

# --- ä¸»é€»è¾‘ï¼šå¤„ç†ä¸Šä¼ çš„æ–‡ä»¶å¹¶è¿›è¡Œé¢„æµ‹ ---
if uploaded_file is not None:
    try:
        if uploaded_file.name.endswith('.csv'):
            input_df = pd.read_csv(uploaded_file)
        else:
            input_df = pd.read_excel(uploaded_file)

        st.subheader("ğŸ“„ æ•°æ®é¢„è§ˆä¸éªŒè¯")
        st.dataframe(input_df.head(), use_container_width=True)

        is_valid = True
        expected_columns = ['price', 'price_delta', 'load', 'load_delta', 'load_capacity_ratio', 'predicted_load',
                            'hour']
        if len(input_df) != 168:
            st.error(f"âŒ æ ¼å¼é”™è¯¯: æ•°æ®å¿…é¡»åŒ…å« 168 è¡Œï¼Œä½†æ‚¨ä¸Šä¼ çš„æ–‡ä»¶æœ‰ {len(input_df)} è¡Œã€‚")
            is_valid = False
        if list(input_df.columns) != expected_columns:
            st.error("âŒ æ ¼å¼é”™è¯¯: åˆ—åæˆ–é¡ºåºä¸æ­£ç¡®ã€‚è¯·å‚ç…§ä¾§è¾¹æ çš„è¯´æ˜è¿›è¡Œæ£€æŸ¥ã€‚")
            st.write("æœŸæœ›åˆ—:", expected_columns)
            st.write("æ‚¨çš„åˆ—:", list(input_df.columns))
            is_valid = False

        if is_valid:
            st.success("âœ… æ•°æ®æ ¼å¼æ­£ç¡®ï¼Œå·²å‡†å¤‡å¥½è¿›è¡Œé¢„æµ‹ã€‚")
            if st.button("ğŸš€ å¼€å§‹é¢„æµ‹æœªæ¥24å°æ—¶ç”µä»·", type="primary", use_container_width=True):
                with st.spinner('ğŸ§  æ­£åœ¨åˆ†ææ•°æ®å¹¶ç”Ÿæˆé¢„æµ‹ï¼Œè¯·ç¨å€™...'):
                    predicted_prices = predict(artifacts, device, input_df)

                st.subheader("ğŸ“Š é¢„æµ‹ç»“æœåˆ†æ")

                # 1. å…³é”®æŒ‡æ ‡å±•ç¤º
                avg_price = predicted_prices.mean()
                max_price = predicted_prices.max()
                min_price = predicted_prices.min()
                col1, col2, col3 = st.columns(3)
                col1.metric("æœªæ¥24hå¹³å‡ç”µä»·", f"{avg_price:.2f}")
                col2.metric("æœªæ¥24hæœ€é«˜ç”µä»·", f"{max_price:.2f}", "å³°å€¼")
                col3.metric("æœªæ¥24hæœ€ä½ç”µä»·", f"{min_price:.2f}", "è°·å€¼")

                # --- åˆ›å»ºé€‰é¡¹å¡ ---
                tab1, tab2 = st.tabs(["ğŸ•’ æ¯å°æ—¶é¢„æµ‹è¯¦æƒ…", "ğŸ“ˆ 15åˆ†é’Ÿå¹³æ»‘è¶‹åŠ¿"])

                # --- Tab 1: æ¯å°æ—¶é¢„æµ‹ ---
                with tab1:
                    st.header("æ¯å°æ—¶ç”µä»·é¢„æµ‹")
                    # åˆ›å»ºå°æ—¶çº§ç»“æœDataFrame
                    hourly_results_df = pd.DataFrame({
                        'é¢„æµ‹æœªæ¥å°æ—¶': range(1, 25),
                        'é¢„æµ‹ç”µä»·': predicted_prices
                    })

                    # ä½¿ç”¨Plotlyç»˜åˆ¶å°æ—¶çº§å›¾è¡¨
                    fig_hourly = go.Figure()
                    fig_hourly.add_trace(go.Scatter(
                        x=hourly_results_df['é¢„æµ‹æœªæ¥å°æ—¶'],
                        y=hourly_results_df['é¢„æµ‹ç”µä»·'],
                        mode='lines+markers',
                        name='é¢„æµ‹ç”µä»·',
                        hovertemplate='æœªæ¥ç¬¬ %{x} å°æ—¶<br>é¢„æµ‹ç”µä»·: %{y:.2f}<extra></extra>'
                    ))
                    fig_hourly.update_layout(
                        title='æœªæ¥24å°æ—¶ç”µä»·é¢„æµ‹è¶‹åŠ¿',
                        xaxis_title='æœªæ¥å°æ—¶æ•° (h)',
                        yaxis_title='ç”µä»·',
                        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
                    )
                    st.plotly_chart(fig_hourly, use_container_width=True)

                    with st.expander("æŸ¥çœ‹è¯¦ç»†é¢„æµ‹æ•°æ® (æ¯å°æ—¶)", expanded=False):
                        st.dataframe(
                            hourly_results_df.style.format({'é¢„æµ‹ç”µä»·': '{:.4f}'}),
                            use_container_width=True
                        )
                        csv_hourly = hourly_results_df.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½æ¯å°æ—¶é¢„æµ‹ç»“æœ (CSV)",
                            data=csv_hourly,
                            file_name='predicted_hourly_prices.csv',
                            mime='text/csv',
                        )

                # --- Tab 2: 15åˆ†é’Ÿå¹³æ»‘è¶‹åŠ¿ ---
                with tab2:
                    st.header("15åˆ†é’Ÿç²’åº¦å¹³æ»‘è¶‹åŠ¿")
                    st.info(
                        "â„¹ï¸ è¿™æ˜¯é€šè¿‡å¯¹æ¯å°æ—¶é¢„æµ‹ç‚¹è¿›è¡Œ**ä¸‰æ¬¡æ ·æ¡æ’å€¼**ç”Ÿæˆçš„æ›²çº¿")

                    # ç”Ÿæˆ15åˆ†é’Ÿç²’åº¦æ•°æ®
                    finer_prices, time_labels, finer_time_points = interpolate_to_15min(predicted_prices)

                    # åˆ›å»º15åˆ†é’Ÿç²’åº¦ç»“æœDataFrame
                    finer_results_df = pd.DataFrame({
                        'æ—¶é—´ç‚¹': time_labels,
                        'å¹³æ»‘ç”µä»·': finer_prices
                    })

                    # ä½¿ç”¨Plotlyç»˜åˆ¶15åˆ†é’Ÿç²’åº¦å›¾è¡¨
                    fig_finer = go.Figure()
                    # ç»˜åˆ¶å¹³æ»‘æ›²çº¿
                    fig_finer.add_trace(go.Scatter(
                        x=finer_time_points + 1,  # xè½´ä»1å¼€å§‹
                        y=finer_prices,
                        mode='lines',
                        name='15åˆ†é’Ÿå¹³æ»‘æ›²çº¿',
                        line=dict(shape='spline', color='rgba(255, 127, 14, 0.8)'),  # ä½¿ç”¨æ©™è‰²å¹³æ»‘çº¿
                        hovertemplate='æ—¶é—´: %{customdata}<br>å¹³æ»‘ç”µä»·: %{y:.2f}<extra></extra>',
                        customdata=time_labels
                    ))
                    # æ ‡è®°åŸå§‹çš„å°æ—¶é¢„æµ‹ç‚¹
                    fig_finer.add_trace(go.Scatter(
                        x=hourly_results_df['é¢„æµ‹æœªæ¥å°æ—¶'],
                        y=hourly_results_df['é¢„æµ‹ç”µä»·'],
                        mode='markers',
                        name='æ¯å°æ—¶é¢„æµ‹ç‚¹',
                        marker=dict(size=8, color='rgba(31, 119, 180, 1)'),
                        hovertemplate='æœªæ¥ç¬¬ %{x} å°æ—¶ (åŸå§‹é¢„æµ‹)<br>é¢„æµ‹ç”µä»·: %{y:.2f}<extra></extra>'
                    ))
                    fig_finer.update_layout(
                        title='æœªæ¥24å°æ—¶ç”µä»·å¹³æ»‘è¶‹åŠ¿ (15åˆ†é’Ÿç²’åº¦)',
                        xaxis_title='æœªæ¥å°æ—¶æ•° (h)',
                        yaxis_title='ç”µä»·',
                        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
                    )
                    st.plotly_chart(fig_finer, use_container_width=True)

                    with st.expander("æŸ¥çœ‹è¯¦ç»†å¹³æ»‘æ•°æ® (15åˆ†é’Ÿ)", expanded=False):
                        st.dataframe(
                            finer_results_df.style.format({'å¹³æ»‘ç”µä»·': '{:.4f}'}),
                            use_container_width=True,
                            height=300  # è®¾ç½®ä¸€ä¸ªæœ€å¤§é«˜åº¦
                        )
                        csv_finer = finer_results_df.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½15åˆ†é’Ÿå¹³æ»‘æ•°æ® (CSV)",
                            data=csv_finer,
                            file_name='predicted_15min_prices.csv',
                            mime='text/csv',
                        )

    except Exception as e:
        st.error(f"å¤„ç†æ–‡ä»¶æˆ–é¢„æµ‹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        st.warning("è¯·ç¡®ä¿æ‚¨çš„æ–‡ä»¶æ˜¯æ ‡å‡†çš„ CSV æˆ– XLSX æ ¼å¼ï¼Œå¹¶ä¸”æ²¡æœ‰æŸåã€‚")

else:
    st.info("ğŸ‘‹ è¯·åœ¨å·¦ä¾§ä¸Šä¼ æ‚¨çš„å†å²æ•°æ®æ–‡ä»¶ä»¥å¯åŠ¨é¢„æµ‹ã€‚")
